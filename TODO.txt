Build up dataset for each emotion
- Collect images for both sets
- Run a face detection on each one to pull out the faces and save them
	- Make sure to check all faces and wait for key press to save or scrap
- Train model on this dataset

Build up the service to handle game requests
- Start game
- Stop game
- Start recalibration process
- Save to database function that can be called when stopping

Pass socket messages from server to script to update the mode
- When inactive until started, active until stopped from socket messages
- When in calibration mode, perform calibration
	- Make robot control calls to count down?
- When in play mode, turn into rounds-oriented system and leave place for robot control calls
- Store play statys when in play mode
- Have play mode call itself again when finished with one round
- When stop message is received, send game stats back to the server and have the server save them to the database

Calibration process overview:
- Math for picking which face to choose in the frame
- Request for re-calibrating when the user goes out of the screen

To get ER repo, clone at top level:
git clone https://github.com/greatsharma/Facial_Emotion_Recognition

Current TODOs:
- Do one more pass on verified images to move any egregious missorts and then get stats
- Finish pipeline node grabbing updated emotion only after confident change (do in lab with webcam)
- Any other testing I can do right now
- Start training tonight (can start to figure out setup at least until I get home)
